{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049bba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from labml_helpers.module import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3ab173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionLayer(Module):\n",
    "    \"\"\"Single graph attention layer\n",
    "    \n",
    "    in features: is the number of input features per node,\n",
    "    out features: is the number of output features per node,\n",
    "    n_heads: number of attention heads\n",
    "    is concat: should the output concatinated or averaged,\n",
    "    dropout: prrobability of dropout,\n",
    "    leaky_relu_negative_slope: negagtive slope for leaky relu activation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features: int, out_features: int, n_heads: int, is_concat: bool = True,\n",
    "                dropout: int = 0.6, leaky_relu_negative_slope: float = 0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.is_concat = is_concat\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        if is_concat:\n",
    "            assert out_features % n_heads == 0\n",
    "            \n",
    "            self.n_hidden = out_features // n_heads\n",
    "        else:\n",
    "            self.n_hidden = out_features\n",
    "            \n",
    "        self.linear = nn.Linear(in_features, self.n_hidden * n_heads, bias=False)\n",
    "        \n",
    "        self.attn = nn.Linear(self.n_hidden * 2, 1, bias=False)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(negative_slope=leaky_relu_negative_slope)\n",
    "        \n",
    "        # to compute attention\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def __call__(self, h: torch.Tensor, adj_mat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        adj_mat is the adjacency matrix of shape [n_nodes, n_nodes, n_heads]. \n",
    "        We use shape [n_nodes, n_nodes, 1] since the adjacency is the same for each head.\n",
    "        \"\"\"\n",
    "        n_nodes = h.shape[0]\n",
    "        # for each head we do a linear transformation and split\n",
    "        g = self.linear(h).view(n_nodes, self.n_heads, self.n_hidden)\n",
    "        # Calculate attention score\n",
    "        \n",
    "        # where each node embedding is repeated n_nodes times.\n",
    "        g_repeat = g.repeat(n_nodes, 1, 1)\n",
    "        \n",
    "        g_repeat_interleave = g.repeat_interleave(n_nodes, dim=0)\n",
    "        \n",
    "        g_concat = torch.cat([g_repeat_interleave, g_repeat], dim=-1)\n",
    "        \n",
    "        # Reshape\n",
    "        g_concat = g_concat.view(n_nodes, n_nodes, self.n_heads, 2 * self.n_hidden)\n",
    "        \n",
    "        e = self.activation(self.attn(g_concat))\n",
    "        \n",
    "        # Remove last dimension\n",
    "        e = e.squeeze(-1)\n",
    "        \n",
    "        # [n_nodes, n_nodes, n_heads] or[n_nodes, n_nodes, 1]\n",
    "        assert adj_mat.shape[0] == 1 or adj_mat.shape[0] == n_nodes\n",
    "        assert adj_mat.shape[1] == 1 or adj_mat.shape[1] == n_nodes\n",
    "        assert adj_mat.shape[2] == 1 or adj_mat.shape[2] == self.n_heads\n",
    "        \n",
    "        # Mask eij based on adjacency matrix. eij is set to −∞ if there is no edge from i to j.\n",
    "        e = e.masked_fill(adj_mat == 0, float('-inf'))\n",
    "        \n",
    "        a = self.softmax(e)\n",
    "        \n",
    "        a = self.dropout(a)\n",
    "        \n",
    "        #Calculate final output for each head\n",
    "        attn_res= torch.einsum('ijh,jhf->ihf', a, g)\n",
    "        \n",
    "        if self.concat:\n",
    "            return attn_res.reshape(n_nodes, self.n_heads * self.n_hidden)\n",
    "        else:\n",
    "            return attn_res.mean(dim=1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6d29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from labml import lab, monit, tracker, experiment\n",
    "from labml.configs import BaseConfigs, option, calculate\n",
    "from labml.utils import download\n",
    "from labml_helpers.device import DeviceConfigs\n",
    "from labml_helpers.module import Module\n",
    "from labml_nn.graphs.gat import GraphAttentionLayer\n",
    "from labml_nn.optimizers.configs import OptimizerConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e761f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraDataset:\n",
    "    \"\"\"\n",
    "    Cora dataset is for research papers,\n",
    "    For each paper we have binary feature vector that indicates the presence of words\n",
    "    Each paper is classified into one of 7 classes\n",
    "    \n",
    "    The papers are the nodes of the graph and the edges are the citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels: torch.Tensor\n",
    "    classes: Dict[str, int]\n",
    "    features: torch.Tensor\n",
    "    adj_mat: torch.Tensor\n",
    "        \n",
    "    @staticmethod\n",
    "    def _download():\n",
    "        if not (lab.get_data_path() / 'cora').exists():\n",
    "            download.download_file('https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz',\n",
    "                                   lab.get_data_path() / 'cora.tgz')\n",
    "            download.extract_tar(lab.get_data_path() / 'cora.tgz', lab.get_data_path())\n",
    "    \n",
    "    def __init__(self, include_edges: bool = True):\n",
    "        self.include_edges = include_edges\n",
    "        \n",
    "        self._download()\n",
    "        \n",
    "        with monit.section('Read content file'):\n",
    "            content = np.genfromtxt(str(lab.get_data_path() / 'cora/cora.content'), dtype=np.dtype(str))\n",
    "            \n",
    "        with monit.section('Read citations file'):\n",
    "            citations = np.genfromtxt(str(lab.get_data_path() / 'cora/cora.cites'), dtype=np.int32)\n",
    "            \n",
    "        features = torch.tensor(np.array(content[:, 1:-1], dtype=np.float32))\n",
    "        \n",
    "        self.features = features / features.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        self.classes = {s: i for i, s in enumerate(set(content[:, -1]))}\n",
    "        \n",
    "        self.labels = torch.tensor([self.classes[i] for i in content[:, -1]], dtype=torch.long)\n",
    "        \n",
    "        paper_ids = np.array(content[:, 0], dtype=np.int32)\n",
    "        \n",
    "        ids_to_idx = {id_: i for i, id_ in enumerate(paper_ids)}\n",
    "        #Mark citations in adj matrix\n",
    "        self.adj_mat = torch.eye(len(self.labels), dtype=torch.bool)\n",
    "        \n",
    "        if self.include_edges:\n",
    "            for e in citations:\n",
    "                e1, e2 = ids_to_idx[e[0]], ids_to_idx[e[1]]\n",
    "                self.adj_mat[e1][e2] = True\n",
    "                self.adj_mat[e2][e1] = True\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2058beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(Module):\n",
    "    \n",
    "    def __init__(self, in_features: int, n_hidden: int, n_classes: int, n_heads: int, dropout: float):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layer1 = GraphAttentionLayer(in_features, n_hidden, n_heads, is_concat=True, dropout=dropout)\n",
    "        \n",
    "        self.activation = nn.ELU()\n",
    "        \n",
    "        self.output = GraphAttentionLayer(n_hidden, n_classes, 1, is_concat=False, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, adj_mat: torch.Tensor):\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer1(x, adj_mat)\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return self.output(x, adj_mat)\n",
    "        \n",
    "        \n",
    "def accuracy(output: torch.Tensor, labels: torch.Tensor):\n",
    "    return output.argmax(dim=-1).eq(labels).sum().item() / len(labels)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93711aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs(BaseConfigs):\n",
    "    model: GAT\n",
    "    training_samples: int = 500\n",
    "    in_features: int\n",
    "    n_hidden: int = 64\n",
    "    n_head: int = 8\n",
    "    n_classes: int\n",
    "    dropout: float = 0.6\n",
    "    include_edges: bool = True\n",
    "    dataset: CoraDataset\n",
    "    epochs: int = 1_000\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    device: torch.device = DeviceConfigs()\n",
    "    optimizer: torch.optim.Adam\n",
    "        \n",
    "    def run(self):\n",
    "        features = self.dataset.features.to(self.device)\n",
    "        \n",
    "        labels = self.dataset.labels.to(self.device)\n",
    "        \n",
    "        edges_adj = self.dataset.adj_mat.to(self.device)\n",
    "        \n",
    "        edges_adj = edges_adj.unsqueeze(-1)\n",
    "        \n",
    "        idx_rand = torch.randperm(len(labels))\n",
    "        \n",
    "        idx_train = idx_rand[:self.training_samples]\n",
    "        \n",
    "        idx_valid = idx_rand[self.training_samples:]\n",
    "        \n",
    "        for epoch in monit.loop(self.epochs):\n",
    "            \n",
    "            self.model.train()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            output = self.model(features, edges_adj)\n",
    "            \n",
    "            loss = self.loss_func(output[idx_train], labels[idx_train])\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            tracker.add('loss.train', loss)\n",
    "            \n",
    "            tracker.add('accuracy.train', accuracy(output[idx_train], labels[idx_train]))\n",
    "            \n",
    "            self.model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(features, edges_adj)\n",
    "                \n",
    "                loss = self.loss_func(output[idx_valid], labels[idx_valid])\n",
    "                \n",
    "                tracker.add('loss.valid', loss)\n",
    "                \n",
    "                tracker.add('accuracy.valid', accuracy(output[idx_valid], labels[idx_valid]))\n",
    "                \n",
    "            tracker.save()\n",
    "            \n",
    "@option(Configs.dataset)\n",
    "def cora_dataset(c: Configs):\n",
    "    return CoraDataset(c.include_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7d9015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(c)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(Configs.n_classes, lambda c: len(c.dataset.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ed3fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(c)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(Configs.in_features, lambda c: c.dataset.features.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7663ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@option(Configs.model)\n",
    "def gat_model(c: Configs):\n",
    "    return GAT(c.in_features, c.n_hidden, c.n_classes, c.n_heads, c.dropout).to(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d363ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@option(Configs.optimizer)\n",
    "def _optimizer(c: Configs):\n",
    "    opt_conf = OptimizerConfigs()\n",
    "    opt_conf.parameters = c.model.parameters()\n",
    "    return opt_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7e12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    conf = Configs()\n",
    "    experiment.create(name='gat')\n",
    "    experiment.configs(conf, {\n",
    "        'optimizer.optimizer': 'Adam',\n",
    "        'optimizer.learning_rate': 5e-3,\n",
    "        'optimizer.weight_decay': 5e-4,\n",
    "    })\n",
    "    \n",
    "    with experiment.start():\n",
    "        conf.run()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1058005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Not a valid git repository: <strong>/Users/kaanbursa/Desktop/AI/Torch/Graph</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "\n",
       "\n",
       "<strong><span style=\"text-decoration: underline\">gat</span></strong>: <span style=\"color: #208FFB\">360a775005c811ecb4adc4b301c9cf33</span>\n",
       "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://app.labml.ai.</strong>\n",
       "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://app.labml.ai/run/360a775005c811ecb4adc4b301c9cf33' target='blank'>https://app.labml.ai/run/360a775005c811ecb4adc4b301c9cf33</a>\n",
       "Prepare dataset...\n",
       "  Read content file<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4,261.72ms</span>\n",
       "  Read citations file<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t27.38ms</span>\n",
       "Prepare dataset<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t6,140.95ms</span>\n",
       "<strong><span style=\"color: #DDB62B\">Still updating app.labml.ai, please wait for it to complete...</span></strong></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xh0f4y0c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36017<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/kaanbursa/Desktop/AI/Torch/Graph/logs/gat/be101a2405b411ecb4adc4b301c9cf33/wandb/run-20210825_175718-xh0f4y0c/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/kaanbursa/Desktop/AI/Torch/Graph/logs/gat/be101a2405b411ecb4adc4b301c9cf33/wandb/run-20210825_175718-xh0f4y0c/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">deep-mountain-2</strong>: <a href=\"https://wandb.ai/kaanb/gat/runs/xh0f4y0c\" target=\"_blank\">https://wandb.ai/kaanb/gat/runs/xh0f4y0c</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:xh0f4y0c). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">balmy-sun-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/kaanb/gat\" target=\"_blank\">https://wandb.ai/kaanb/gat</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/kaanb/gat/runs/3i3ow8dn\" target=\"_blank\">https://wandb.ai/kaanb/gat/runs/3i3ow8dn</a><br/>\n",
       "                Run data is saved locally in <code>/Users/kaanbursa/Desktop/AI/Torch/Graph/logs/gat/360a775005c811ecb4adc4b301c9cf33/wandb/run-20210825_201640-3i3ow8dn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "Configs has no attribute `n_heads`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-aa67acacfb99>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-613d1ee78b79>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/labml/internal/configs/base.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/labml/internal/configs/base.py\u001b[0m in \u001b[0;36m__calculate\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mmonit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Prepare {item}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mcalc_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/labml/internal/configs/config_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFunctionKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-40329b17c8a7>\u001b[0m in \u001b[0;36mgat_model\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/labml/internal/configs/base.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/labml/internal/configs/base.py\u001b[0m in \u001b[0;36m__calculate\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__} has no attribute `{item}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_STANDARD_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             config_function = ConfigFunction(self.__types[item],\n",
      "\u001b[0;31mAttributeError\u001b[0m: Configs has no attribute `n_heads`"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #208FFB\">Updating App. Please wait...</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><strong><span style=\"color: #DDB62B\">Finished updating LabML App.</span></strong></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be952b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
